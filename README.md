# Data Science Bootcamp: Repo 3 (Days 21‚Äì30)

Welcome to **Repo 3** of the 100 Days of Code ‚Äì Data Science Bootcamp!  
This phase focuses on **Machine Learning (ML) fundamentals**, applying concepts learned in the first two repos to real-world datasets.

---

## üìÖ Roadmap

### Day 21 ‚Äì Introduction to Machine Learning

**Concepts Covered:**
- What is Machine Learning? Supervised vs. Unsupervised.
- The ML workflow: data prep ‚Üí training ‚Üí evaluation.
- Introduction to regression with real housing data.

**Practice:**
- Loaded the California Housing dataset (`fetch_california_housing`).
- Split data into training/testing sets.
- Trained and evaluated a Linear Regression model.

**Mini Project: Predict California Housing Prices**
- Built a regression model on the California dataset.
- Evaluated model with MSE and R¬≤ score.
- Identified important features driving housing prices.


## Day 22 ‚Äì Linear Regression Deep Dive (Ames Housing)

**Concepts Covered:**
- Multiple Linear Regression.
- Model assumptions: linearity, independence, homoscedasticity, normality, multicollinearity.
- Metrics: MSE, R¬≤ Score.

**Practice:**
- Loaded Ames Housing dataset from OpenML.
- Trained multiple regression using numeric features.
- Evaluated model with MSE and R¬≤.
- Visualized residuals and feature importance.

**Mini Project: Predict House Prices (Variation)**
- Built regression model with a subset of 10 features.
- Compared reduced vs full-feature model.
- Plotted actual vs predicted prices.
- Reflected on most important predictors of house prices.


### Day 23 ‚Äì Logistic Regression
- Classification basics, decision boundaries, odds/logits.
- Practice with binary classification.
- Mini Project: Predict Titanic survival.

### Day 24 ‚Äì k-Nearest Neighbors (k-NN)
- Distance-based models, curse of dimensionality.
- Hyperparameter tuning with GridSearch.
- Mini Project: Classify wine quality (scaled dataset).

### Day 25 ‚Äì Decision Trees
- Gini vs. Entropy, tree depth, overfitting.
- Visualization of decision boundaries.
- Mini Project: Build a decision tree classifier.

### Day 26 ‚Äì Random Forests
- Ensemble methods, bagging, feature importance.
- Compare single trees vs. forests.
- Mini Project: Predict diabetes outcomes.

### Day 27 ‚Äì Support Vector Machines (SVM)
- Margin maximization, kernels, soft margins.
- Practice with linear + RBF kernels.
- Mini Project: Handwritten digit recognition (MNIST subset).

### Day 28 ‚Äì Clustering (Unsupervised Learning)
- k-Means, silhouette score, elbow method.
- Mini Project: Customer segmentation.

### Day 29 ‚Äì PCA (Dimensionality Reduction)
- Eigenvalues, eigenvectors, explained variance.
- Mini Project: Visualize high-dimensional data.

### Day 30 ‚Äì Major Project: ML Pipeline
- End-to-end ML workflow: data cleaning, scaling, feature selection, model training, evaluation.
- Suggested Dataset: Wine Quality, Titanic, or a real-world dataset of your choice.
- Deliverable: Full Jupyter notebook + README write-up.

---

## üõ†Ô∏è Tools & Libraries
- `scikit-learn`
- `pandas`
- `numpy`
- `matplotlib` / `seaborn`

---

## üéØ Major Project (Day 30)
At the end of Repo 3, you‚Äôll build a **complete ML pipeline**:
- Load & clean data.
- Explore & preprocess.
- Train multiple ML models.
- Evaluate & compare performance.
- Present insights & recommendations.

---
